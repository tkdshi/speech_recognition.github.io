<p>
    <html lang="ja">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
        <meta http-equiv="Content-Style-Type" content="text/css">
        <meta http-equiv="Content-Script-Type" content="text/javascript">
        <title>Spoken Dialog by Javascript</title>
    </head>
    <body>
    <h1>課題：音声対話</h1>
<p>
    <button id="startButton">start</button>
    <button id="stopButton">stop</button>
</p>
<p>
<div id="resultOutput"></div>
</p>
<script>
    const startButton = document.querySelector('#startButton'); // 開始ボタン
    const stopButton = document.querySelector('#stopButton'); // 停止ボタン
    const resultOutput = document.querySelector('#resultOutput'); // 結果出力エリア

    if (!'SpeechSynthesisUtterance' in window) {
        alert("あなたのブラウザはSpeech Synthesis APIに未対応です。");
    }
    const tts = new SpeechSynthesisUtterance(); // TTSインスタンスを生成
    //tts.text = textForm.value; // テキストを設定
    tts.lang = "ja-JP"; // 言語(日本語)、英語の場合はen-US
    tts.rate = 1.0; // 速度
    tts.pitch = 1.0; // 声の高さ
    tts.volume = 1.0; // 音量

    var archive = new Array(100); //結果の履歴を格納する
    var time = 0; //試行回数

    SpeechRecognition = webkitSpeechRecognition || SpeechRecognition;
    if (!'SpeechRecognition' in window) {
        alert("あなたのブラウザはSpeech Recognition APIに未対応です。");
    }

    const asr = new SpeechRecognition(); // ASRインスタンスを生成
    asr.lang = "ja-JP"; // 言語（日本語）
    asr.interimResults = true; // 途中結果出力をオン
    asr.continuous = true; // 継続入力をオン

    let output = ''; // 出力


    // 認識結果が出力されたときのイベントハンドラ
    asr.onresult = function (event) {
        // 応答の定義（ハッシュ）
        var response = {
            "あなた,誰": "わたしはアレクサではありません",
            "何歳": "え、わたし、何歳にみえますか",
            "元気": "元気ですよー",
            "好きな,食べ物": "焼肉です",
            "昨日,天気": "昨日の天気はくもりでした",
            "今日,天気": "今日の天気は晴れです",
            "明日,天気": "明日の天気は雨です",
            "昨日,授業": "昨日はデザイン情報総合演習がありました",
            "今日,授業": "今日はメディアデザインセミナーがあります",
            "明日,授業": "明日はイメージ情報処理があります",
        };

        //そのまま返答する応答の定義（あいさつ）
        var message = new Array("こんにちは", "こんばんは", "おはようございます", "おはよう", "ありがとう", "さようなら");

        let transcript = event.results[event.resultIndex][0].transcript; // 結果文字
        let output_not_final = '';
        if (event.results[event.resultIndex].isFinal) { // 結果が確定（Final）のとき
            asr.abort(); // 音声認識を停止
            let answer = response[transcript];


            tts.text = "";
            var flag = 0;

            //入力した音声が部分的に一致しているか確認
            let keys = Object.keys(response);
            keys.forEach(function (key) {
                let flag2 = true;
                console.log(transcript);
                key.split(',').forEach(function (word) {
                    let pattern = new RegExp(word);
                    let flag_test = pattern.test(transcript); // マッチしたらtrue, しなかったらfalse
                    flag2 = flag2 && flag_test; // 両方trueならtrue
                    console.log(pattern + '+' + ':' + flag_test);
                    //flag = flag && new RegExp(word).test(transcript);

                });
                if (flag2) {
                    answer = response[key];
                    console.log(key + " : " + answer);
                    flag = 1;
                    archive[time] = answer;
                    time++;
                }
            });


            //入力した音声があいさつと一致しているか確認
            message.forEach(function (value) {
                if (value == transcript) {
                    answer = value;
                    flag = 1;

                }
            });


            //入力した音声が今までの履歴と同じであるか確認
            var i;
            for (i = 1; i < time; i++) {
                if (answer == archive[i - 1]) {
                    answer = "もう一度お答えします、" + answer;
                }
            }

            if (flag == 0) {
                answer = "すみません、もう一度お試しください";
            }

            output += '<ul><li class="question">' + transcript + '</li><li class="answer">' + answer + '</li></ul><br>';

            tts.text = answer;

            // 再生が終了（end）ときのイベントハンドラ（終了したときに実行される）
            tts.onend = function (event) {
                asr.start(); // 音声認識を再開
            }

            speechSynthesis.speak(tts); // 再生
        } else { // 結果がまだ未確定のとき
            output_not_final = '<ul><li class="question_pre"><span style="color:#ddd;">' + transcript + '</span></li></ul>';
        }
        resultOutput.innerHTML = output + output_not_final;
    }

    // 開始ボタンのイベントハンドラ
    startButton.addEventListener('click', function () {
        asr.start();
    })

    // 停止ボタンのイベントハンドラ
    stopButton.addEventListener('click', function () {
        asr.stop();
    })


</script>
</body>
</html>
</p>