<p>
    <html lang="ja">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
        <meta http-equiv="Content-Style-Type" content="text/css">
        <meta http-equiv="Content-Script-Type" content="text/javascript">
        <link rel="stylesheet" href="index.css">
        <!-- CSS only -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
              integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk"
              crossorigin="anonymous">

        <!-- JS, Popper.js, and jQuery -->
        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
                integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
                crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
                integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
                crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
                integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
                crossorigin="anonymous"></script>
        <audio id="start" preload="auto">
            <source src="https://soundeffect-lab.info/sound/button/mp3/cursor3.mp3" type="audio/mp3">
        </audio>
        <title>speech_recognition.github.io</title>
    </head>
    <body>

    <h1>音声対話アプリケーション</h1>
<p>
    <button type="button" class="btn btn-primary" id="startButton">Start</button>
    <button type="button" class="btn btn-primary" id="stopButton">Stop</button>
</p>
<div id="resultOutput">
    <p>
        「Start」をクリックしてマイクの認識を開始します。<br>「おはよう」「こんにちは」などの声をかけると、AIの認識を開始します
    </p>
</div>
<script>
    function sound() {
        // [ID:sound-file]の音声ファイルを再生[play()]する
        document.getElementById('start').play();
    }

    const URL = "https://jlp.yahooapis.jp/NLUService/V1/analyze?appid="; // APIのリクエストURL
    const APIID = "dj00aiZpPXBiQjY2N1R3M09iaCZzPWNvbnN1bWVyc2VjcmV0Jng9NmM-"; // アプリケーションID

    const startButton = document.querySelector('#startButton'); // 開始ボタン
    const stopButton = document.querySelector('#stopButton'); // 停止ボタン
    const resultOutput = document.querySelector('#resultOutput'); // 結果出力エリア

    if (!'SpeechSynthesisUtterance' in window) {
        alert("あなたのブラウザはSpeech Synthesis APIに未対応です。");
    }
    const tts = new SpeechSynthesisUtterance(); // TTSインスタンスを生成
    //tts.text = textForm.value; // テキストを設定
    tts.lang = "ja-JP"; // 言語(日本語)、英語の場合はen-US
    tts.rate = 1.0; // 速度
    tts.pitch = 1.0; // 声の高さ
    tts.volume = 1.0; // 音量

    var archive = new Array(100); //結果の履歴を格納する
    var time = 0; //試行回数

    SpeechRecognition = webkitSpeechRecognition || SpeechRecognition;
    if (!'SpeechRecognition' in window) {
        alert("あなたのブラウザはSpeech Recognition APIに未対応です。");
    }

    const asr = new SpeechRecognition(); // ASRインスタンスを生成
    asr.lang = "ja-JP"; // 言語（日本語）
    asr.interimResults = true; // 途中結果出力をオン
    asr.continuous = true; // 継続入力をオン

    let output = ''; // 出力
    var start = 0;　//ウェイクワードの判定で使用
    tts.text = "";

    // 認識結果が出力されたときのイベントハンドラ
    asr.onresult = function (event) {
        // 応答の定義（ハッシュ）
        var response = {
            "あなた,誰": "わたしはアレクサではありません",
            "何歳": "え、わたし、何歳にみえますか",
            "元気": "元気ですよー",
            "好きな,食べ物": "焼肉です",
            "昨日,天気": "昨日の天気はくもりでした",
            "今日,天気": "今日の天気は晴れです",
            "明日,天気": "明日の天気は雨です",
            "昨日,授業": "昨日はデザイン情報総合演習がありました",
            "今日,授業": "今日はメディアデザインセミナーがあります",
            "明日,授業": "明日はイメージ情報処理があります",
        };

        var search = new Array("検索", "調べる");

        //そのまま返答する応答の定義（あいさつ）
        var message = new Array("こんにちは", "こんばんは", "おはようございます", "おはよう");

        let transcript = event.results[event.resultIndex][0].transcript; // 結果文字
        let output_not_final = '';
        if (event.results[event.resultIndex].isFinal) { // 結果が確定（Final）のとき
            var flag = 0;
            let answer = response[transcript];
            //入力した音声があいさつと一致しているか確認
            message.forEach(function (value) {
                if (value == transcript) {
                    answer = value;
                    flag = 1;
                    if (start == 0) {
                        sound();
                        start = 1; //ウェイクワードの判定をtrueにする
                    }
                }
            });
            if (start == 1) {
                asr.abort(); // 音声認識を停止

                //入力した音声が部分的に一致しているか確認
                let keys = Object.keys(response);
                keys.forEach(function (key) {
                    let flag2 = true;
                    console.log(transcript);
                    key.split(',').forEach(function (word) {
                        let pattern = new RegExp(word);
                        let flag_test = pattern.test(transcript); // マッチしたらtrue, しなかったらfalse
                        flag2 = flag2 && flag_test; // 両方trueならtrue
                        console.log(pattern + '+' + ':' + flag_test);
                        //flag = flag && new RegExp(word).test(transcript);

                    });
                    if (flag2) {
                        answer = response[key];
                        console.log(key + " : " + answer);
                        flag = 1;
                        archive[time] = answer;
                        time++;
                    }
                });
                //入力した音声が今までの履歴と同じであるか確認
                var i;
                for (i = 1; i < time; i++) {
                    if (answer == archive[i - 1]) {
                        answer = "もう一度お答えします、" + answer;
                    }
                }

                ////入力した音声をAPIに通す
                if (flag == 1) {
                    output += '<div class="msg question"><p class="text">' + transcript + '</div><div class="msg answer"></p><p class="text">' + answer + '</p></div>';
                    resultOutput.innerHTML = output + output_not_final;
                    tts.text = answer;
                    speechSynthesis.speak(tts); // 再生

                } else {
                    let queryURL = URL + APIID + "&intext=" + transcript;
                    console.log(queryURL);

                    // HTTPリクエストの準備
                    const request = new XMLHttpRequest();
                    request.open('GET', queryURL, true);
                    request.responseType = 'json'; // レスポンスはJSON形式に変換
                    // HTTPの状態が変化したときのイベントハンドラ
                    request.onreadystatechange = function () {
                        if (this.readyState == 4 && this.status == 200) {
                            // readyState == 4 操作完了
                            // status == 200 リクエスト成功（HTTPレスポンス）

                            let res = this.response; // 結果はJSON形式

                            Object.keys(res.result).forEach(function (key) {
                                console.log(key + ": " + res.result[key])
                            });

                            // method が SAY のときのみ
                            if (res.result.method == "SAY") {
                                console.log("あああ");
                                flag = 1;
                                answer = res.result.param_text_tts || res.result.param_text;


                                output += '<div class="msg question"><p class="text">' + transcript + '</div><div class="msg answer"></p><p class="text">' + answer + '</p></div>';
                                resultOutput.innerHTML = output + output_not_final;
                                tts.text = answer;
                                speechSynthesis.speak(tts); // 再生
                            }
                        }
                    };
                    request.send();
                }

                if (flag == 0) {
                    answer = "すみません、もう一度お試しください";
                }

                // 再生が終了（end）ときのイベントハンドラ（終了したときに実行される）
                tts.onend = function (event) {
                    asr.start(); // 音声認識を再開
                }

            } else {
                output += '<p>「おはよう」「こんにちは」などの声をかけると、AIの認識を開始します</p>';
            }
        } else { // 結果がまだ未確定のとき
            output_not_final = '<div class="msg question_pre"><p class="text">' + transcript + '</p></div>';
            resultOutput.innerHTML = output + output_not_final;
        }

    }

    // 開始ボタンのイベントハンドラ
    startButton.addEventListener('click', function () {
        asr.start();
    })

    // 停止ボタンのイベントハンドラ
    stopButton.addEventListener('click', function () {
        asr.stop();
    })


</script>
</body>
</html>
</p>